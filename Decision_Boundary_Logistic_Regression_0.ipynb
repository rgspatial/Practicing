{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP1vq/SjiIZy1pbydd0TJ/6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rgspatial/Practicing/blob/main/Decision_Boundary_Logistic_Regression_0.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WGWib8Fm3tKj"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "%matplotlib widget\n",
        "import matplotlib.pyplot as plt\n",
        "from lab_utils_common import plot_data, sigmoid, draw_vthresh\n",
        "plt.style.use('./deeplearning.mplstyle')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dataset\n",
        "Let's suppose you have following training dataset\n",
        "\n",
        "The input variable X is a numpy array which has 6 training examples, each with two features\n",
        "The output variable y is also a numpy array with 6 examples, and y is either 0 or 1"
      ],
      "metadata": {
        "id": "kOahQWCq34QB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[0.5, 1.5], [1,1], [1.5, 0.5], [3, 0.5], [2, 2], [1, 2.5]])\n",
        "y = np.array([0, 0, 0, 1, 1, 1]).reshape(-1,1) "
      ],
      "metadata": {
        "id": "01d_uq7k3yoO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Plot data\n",
        "Let's use a helper function to plot this data. The data points with label  ğ‘¦=1  are shown as red crosses, while the data points with label  ğ‘¦=0  are shown as blue circles."
      ],
      "metadata": {
        "id": "hHf08YqK36zu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fig,ax = plt.subplots(1,1,figsize=(4,4))\n",
        "plot_data(X, y, ax)\n",
        "\n",
        "ax.axis([0, 4, 0, 3.5])\n",
        "ax.set_ylabel('$x_1$')\n",
        "ax.set_xlabel('$x_0$')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "OeREWRuW3ymM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Logistic regression model\n",
        "Suppose you'd like to train a logistic regression model on this data which has the form\n",
        "\n",
        "ğ‘“(ğ‘¥)=ğ‘”(ğ‘¤0ğ‘¥0+ğ‘¤1ğ‘¥1+ğ‘) \n",
        "where  ğ‘”(ğ‘§)=11+ğ‘’âˆ’ğ‘§ , which is the sigmoid function\n",
        "\n",
        "Let's say that you trained the model and get the parameters as  ğ‘=âˆ’3,ğ‘¤0=1,ğ‘¤1=1 . That is,\n",
        "\n",
        "ğ‘“(ğ‘¥)=ğ‘”(ğ‘¥0+ğ‘¥1âˆ’3) \n",
        "(You'll learn how to fit these parameters to the data further in the course)\n",
        "\n",
        "Let's try to understand what this trained model is predicting by plotting its decision boundary\n",
        "\n",
        "Refresher on logistic regression and decision boundary\n",
        "Recall that for logistic regression, the model is represented as\n",
        "\n",
        "ğ‘“ğ°,ğ‘(ğ±(ğ‘–))=ğ‘”(ğ°â‹…ğ±(ğ‘–)+ğ‘)(1)\n",
        "where ğ‘”(ğ‘§) is known as the sigmoid function and it maps all input values to values between 0 and 1:\n",
        "\n",
        "ğ‘”(ğ‘§)=11+ğ‘’âˆ’ğ‘§(2)and ğ°â‹…ğ± is the vector dot product:\n",
        "\n",
        "ğ°â‹…ğ±=ğ‘¤0ğ‘¥0+ğ‘¤1ğ‘¥1\n",
        "We interpret the output of the model (ğ‘“ğ°,ğ‘(ğ‘¥)) as the probability that ğ‘¦=1 given ğ± and parameterized by ğ° and ğ‘.\n",
        "\n",
        "Therefore, to get a final prediction (ğ‘¦=0 or ğ‘¦=1) from the logistic regression model, we can use the following heuristic -\n",
        "if ğ‘“ğ°,ğ‘(ğ‘¥)>=0.5, predict ğ‘¦=1\n",
        "if ğ‘“ğ°,ğ‘(ğ‘¥)<0.5, predict ğ‘¦=0\n",
        "Let's plot the sigmoid function to see where ğ‘”(ğ‘§)>=0.5"
      ],
      "metadata": {
        "id": "32m3JGFt4FvZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot sigmoid(z) over a range of values from -10 to 10\n",
        "z = np.arange(-10,11)\n",
        "\n",
        "fig,ax = plt.subplots(1,1,figsize=(5,3))\n",
        "# Plot z vs sigmoid(z)\n",
        "ax.plot(z, sigmoid(z), c=\"b\")\n",
        "\n",
        "ax.set_title(\"Sigmoid function\")\n",
        "ax.set_ylabel('sigmoid(z)')\n",
        "ax.set_xlabel('z')\n",
        "draw_vthresh(ax,0)"
      ],
      "metadata": {
        "id": "lksSPTcl3ykN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As you can see,  ğ‘”(ğ‘§)>=0.5  for  ğ‘§>=0 \n",
        "For a logistic regression model,  ğ‘§=ğ°â‹…ğ±+ğ‘ . Therefore,\n",
        "\n",
        "if  ğ°â‹…ğ±+ğ‘>=0 , the model predicts  ğ‘¦=1 \n",
        "if  ğ°â‹…ğ±+ğ‘<0 , the model predicts  ğ‘¦=0 \n",
        "Plotting decision boundary\n",
        "Now, let's go back to our example to understand how the logistic regression model is making predictions.\n",
        "\n",
        "Our logistic regression model has the form\n",
        "\n",
        "ğ‘“(ğ±)=ğ‘”(âˆ’3+ğ‘¥0+ğ‘¥1) \n",
        "From what you've learnt above, you can see that this model predicts  ğ‘¦=1  if  âˆ’3+ğ‘¥0+ğ‘¥1>=0 \n",
        "Let's see what this looks like graphically. We'll start by plotting  âˆ’3+ğ‘¥0+ğ‘¥1=0 , which is equivalent to  ğ‘¥1=3âˆ’ğ‘¥0 ."
      ],
      "metadata": {
        "id": "Dmxpy0uJ4px2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Choose values between 0 and 6\n",
        "x0 = np.arange(0,6)\n",
        "\n",
        "x1 = 3 - x0\n",
        "fig,ax = plt.subplots(1,1,figsize=(5,4))\n",
        "# Plot the decision boundary\n",
        "ax.plot(x0,x1, c=\"b\")\n",
        "ax.axis([0, 4, 0, 3.5])\n",
        "\n",
        "# Fill the region below the line\n",
        "ax.fill_between(x0,x1, alpha=0.2)\n",
        "\n",
        "# Plot the original data\n",
        "plot_data(X,y,ax)\n",
        "ax.set_ylabel(r'$x_1$')\n",
        "ax.set_xlabel(r'$x_0$')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "Tt_o5wbw3yh5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the plot above, the blue line represents the line  ğ‘¥0+ğ‘¥1âˆ’3=0  and it should intersect the x1 axis at 3 (if we set  ğ‘¥1  = 3,  ğ‘¥0  = 0) and the x0 axis at 3 (if we set  ğ‘¥1  = 0,  ğ‘¥0  = 3).\n",
        "The shaded region represents  âˆ’3+ğ‘¥0+ğ‘¥1<0 . The region above the line is  âˆ’3+ğ‘¥0+ğ‘¥1>0 .\n",
        "Any point in the shaded region (under the line) is classified as  ğ‘¦=0 . Any point on or above the line is classified as  ğ‘¦=1 . This line is known as the \"decision boundary\".\n",
        "As we've seen in the lectures, by using higher order polynomial terms (eg:  ğ‘“(ğ‘¥)=ğ‘”(ğ‘¥20+ğ‘¥1âˆ’1) , we can come up with more complex non-linear boundaries."
      ],
      "metadata": {
        "id": "YzkBQiz14y3v"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8kysei_Z3yfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "6i83FopH3ydg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "TYnVSgiz3yTy"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}